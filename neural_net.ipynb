{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need three layers\n",
    "\n",
    "# Input neurons are the intensities of the pixels: i x j pixels means i x j input neurons\n",
    "\n",
    "# x is a 28 x 28 = 784 dimensional input vector, which is the image of a single digit\n",
    "\n",
    "# each value in the vector indicates what shade of grey a pixel is between white and black \n",
    "\n",
    "# y is a 10 dimensional output vector, one value for each digit between 0-9\n",
    "\n",
    "# if the network decides on 5 for a given training image, the output vector will be y(x) = (0, 0, 0, 0, 1, 0, 0, 0, 0, 0) transposed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron: \n",
    "    \"A simple neuron\" \n",
    "    \n",
    "    def z(self, w, a, b): # w is a matrix of weights between two layers, \n",
    "                          # a is vector with the activations of the preceding layer, \n",
    "                          # b is a vector with the biases of the computed layer \n",
    "        \"\"\" The input of the neuron \"\"\"\n",
    "        z = w * a + b\n",
    "        return z\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\" The output of the neuron \"\"\"\n",
    "        output = 1 / (1 + np.exp(-z)) # z is the resulting vector, \n",
    "                                      # Numpy applies the sigmoid function elementwise\n",
    "        return output # this is the output vector, which will be the activation vector for the next layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, sizes): # 'sizes' is a list, with each element being the number of neurons in a layer\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes \n",
    "        self.biases = [np.random.randn(j, 1) for j in sizes[1:]] # a vector of initial biases, excluding the input layer\n",
    "        self.weights = [np.random.randn(j, k) for k, j in zip(sizes[:-1], sizes[1:])] # j and k were swapped deliberately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
